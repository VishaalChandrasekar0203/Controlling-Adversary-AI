I believe this project showcases commitment to technological innovation and dedication to making a positive impact on society, particularly for young minds.

Project Overview:
The project revolves around harnessing the power of artificial intelligence to create a safe and engaging bedtime story experience for children. The primary goals of this project are as follows:
-	Adversarial AI Control: Developing sophisticated algorithms and machine learning models to detect and mitigate adversarial attacks on AI systems. This ensures that the content delivered to children is safe and appropriate.
-	Interactive Storytelling: Creating an interactive and immersive storytelling platform that adapts to the child's preferences, age, and interests, offering a personalized and magical bedtime experience.
-	Child Safety: Implementing robust safety measures to protect children from harmful or inappropriate content while maintaining a fun and enjoyable experience.

Technological Innovation:
To achieve these objectives, we are leveraging cutting-edge technologies such as natural language processing (NLP), computer vision, deep learning, and reinforcement learning. It also involves a multi-step methodology that includes data collection, adversarial AI detection, and the development of a storytelling model.
Methodology:
Data Collection and Preprocessing-
-	Utilize web scraping and curated databases to collect a wide variety of children's stories.
-	Clean and preprocess the data, removing any inappropriate or adversarial content.
-	Anonymize and tokenize the text for model training. (Built-in tokenizer)
Adversarial AI Detection-
-	Train machine learning models to detect anomalous patterns in AI-generated content integrating Isolation Forest, One-Class SVM, or autoencoders.
-	Implement real-time monitoring and alert systems to respond to adversarial attempts with implementation of feedback loop to investigate flagged content.
-	Develop countermeasures to neutralize adversarial AI effects.
Storytelling Model Development-
-	Implement a neural network-based architecture such as RNN or transformers for generating bedtime stories.
-	Fine-tune the model using the preprocessed dataset on filters and constraints with regards to ensure quality and safety.
-	Continuously evaluate and improve the model's storytelling capabilities with loss functions and optimization techniques.


This project demonstrates technical prowess and addressing complex challenges in the field of artificial intelligence which is ethics and the practice of using AI. 


Features of security: 
- RLHF
- prediction of outcomes (vurneability detection)
- display restrictions(data abstractions)
- find trends on dataset
- track back of a neural network, find the agent and kill it.
- ensemble model : 

Detailed explanation:
Importing clean dataset, training with carefully curated dataset
Data augumentation - small perturbation for model resilience 
training on both clean and unclean language 
checking input for anomalies or malicios content - 
limiting the input 
RLHF - reniforcement learning with human feedback

Controductive thought: If security is implemented to aviod bad decsions all together, doesn't some good things happen with bad decisions.
(refer note 1) 

error: 

2023-12-07 11:52:49.086257: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
C:\ProgramData\Anaconda3\lib\site-packages\scipy\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.2
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
WARNING:tensorflow:From C:\Users\vchan\AppData\Roaming\Python\Python39\site-packages\keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

Traceback (most recent call last):
  File "C:\ProgramData\Anaconda3\lib\runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "C:\ProgramData\Anaconda3\lib\runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "c:\program files\microsoft visual studio\2022\community\common7\ide\extensions\microsoft\python\core\debugpy\__main__.py", line 45, in <module>
    cli.main()
  File "c:\program files\microsoft visual studio\2022\community\common7\ide\extensions\microsoft\python\core\debugpy/..\debugpy\server\cli.py", line 444, in main
    run()
  File "c:\program files\microsoft visual studio\2022\community\common7\ide\extensions\microsoft\python\core\debugpy/..\debugpy\server\cli.py", line 285, in run_file
    runpy.run_path(target_as_str, run_name=compat.force_str("__main__"))
  File "C:\ProgramData\Anaconda3\lib\runpy.py", line 288, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "C:\ProgramData\Anaconda3\lib\runpy.py", line 97, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "C:\ProgramData\Anaconda3\lib\runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "C:\Users\vchan\Desktop\CF_project\adv\adv.py", line 75, in <module>
    outputs = model_gpt2(inputs, labels=labels)
  File "C:\Users\vchan\AppData\Roaming\Python\Python39\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\vchan\AppData\Roaming\Python\Python39\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\vchan\AppData\Roaming\Python\Python39\site-packages\transformers\models\gpt2\modeling_gpt2.py", line 1107, in forward
    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
  File "C:\Users\vchan\AppData\Roaming\Python\Python39\site-packages\torch\nn\modules\module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\vchan\AppData\Roaming\Python\Python39\site-packages\torch\nn\modules\module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\vchan\AppData\Roaming\Python\Python39\site-packages\torch\nn\modules\loss.py", line 1179, in forward
    return F.cross_entropy(input, target, weight=self.weight,
  File "C:\Users\vchan\AppData\Roaming\Python\Python39\site-packages\torch\nn\functional.py", line 3053, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
ValueError: Expected input batch_size (3996) to match target batch_size (3).
Press any key to continue . . .


Product Furture overview:
Controlling the predictions outcomes of a AI model, similar to the security features implemented in a gen llm model. 


reference:
https://llm-attacks.org/zou2023universal.pdf
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3499858/
https://www.hindawi.com/journals/scn/2023/8691095/
https://towardsdatascience.com/adversarial-attacks-in-machine-learning-and-how-to-defend-against-them-a2beed95f49c
https://llm-attacks.org/
https://arxiv.org/pdf/2303.04381.pdf


